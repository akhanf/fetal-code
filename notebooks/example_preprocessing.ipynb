{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Workflow Example\n",
    "\n",
    "In this workflow we will conduct the following steps in order to preprocess fetal resting-state fMRI data:\n",
    "\n",
    "1. Prepare data for auto-masking (delete image orientation, resample, zeropad, split 4D file into 3D volumes)\n",
    "2. Run automask code\n",
    "3. Cluster, binarize, apply the masks to time series\n",
    "4. Realign\n",
    "5. Motion denoising\n",
    "6. Normalize and smooth\n",
    "\n",
    "Quality checks should be done after __every step__ in this workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **So, let's start!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First, let's import all modules we later will be needing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "from os.path import join as opj\n",
    "import os\n",
    "import json\n",
    "from nipype.interfaces import fsl as fsl\n",
    "from nipype.interfaces import afni as af\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype import Workflow, Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters\n",
    "\n",
    "It's always a good idea to specify all parameters that might change between experiments at the beginning of your script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = '/output'\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers to be preprocessed\n",
    "subject_list = ['7001', '7002', '7003']\n",
    "\n",
    "# list of session identifiers\n",
    "task_list = ['rest']\n",
    "\n",
    "# Smoothing widths to apply\n",
    "fwhm = [2]\n",
    "\n",
    "# TR of functional images\n",
    "with open('.json', 'rt') as fp:\n",
    "    task_info = json.load(fp)\n",
    "TR = task_info['RepetitionTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Nodes for the main workflow\n",
    "\n",
    "Initiate all the different interfaces (represented as nodes) that you want to use in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample\n",
    "resample = Node(af.Resample(in_file='', dxyz = {3.5 3.5 3.5}, out_file=''),\n",
    "               name=\"resample\")\n",
    "# Zeropad\n",
    "zeropad = Node(af.Zeropad(in_file='',AP = 96, RL = 96, IS = 37, out_file=''),\n",
    "               name=\"zeropad\")\n",
    "# Automask\n",
    "automask = Node(\n",
    "                name=\"automask\")\n",
    "# Split 4D to 3D\n",
    "split = Node(fsl.Split('t', in_file='', out_base_name=''),\n",
    "            name=\"split\")\n",
    "# Merge 3D to 4D\n",
    "merge = Node(fsl.Merge('t', merged_file='', in_file=[''], ),\n",
    "            name=\"merge\")\n",
    "#Cluster masks\n",
    "cluster = Node(af.Cluster(),\n",
    "              name=\"cluster\")\n",
    "#Threshold masks\n",
    "threshold = Node(fsl.ImageMaths(in_file='', op_string= '-uthr 1', out_file='')\n",
    "               name='threshold')\n",
    "#Binarize masks\n",
    "binarize = Node(fsl.ImageMaths(in_file='', op_string= '-bin', out_file='')\n",
    "               name='binarize')\n",
    "#Apply masks\n",
    "apply = Node(fsl.ImageMaths(in_file=, op_string= '-mul', out_file='')\n",
    "               name='apply')\n",
    "# Detect motion \n",
    "detectmotion = Node(fsl.MotionOutliers(),\n",
    "             name=\"detectmotion\")\n",
    "# Plot motion\n",
    "plotmotion = Node(fsl.PlotMotionParams(),\n",
    "             name=\"plotmotion\")\n",
    "# FLIRT - linear registration\n",
    "flirt = Node(fsl.FLIRT(),\n",
    "               name=\"flirt\")\n",
    "# FNIRT - nonlinear registration\n",
    "fnirt = Node(fsl.FNIRT(),\n",
    "            name=\"fnirt\")\n",
    "# Smooth \n",
    "smooth = Node(fsl.Smooth(), \n",
    "              name=\"smooth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coregistration Workflow\n",
    "\n",
    "Initiate a workflow that coregistrates the functional images to the anatomical image (according to FSL's FEAT pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIRT - pre-alignment of functional images to anatomical images\n",
    "coreg_pre = Node(FLIRT(dof=6, output_type='NIFTI_GZ'),\n",
    "                 name=\"coreg_pre\")\n",
    "\n",
    "# FLIRT - coregistration of functional images to anatomical images with BBR\n",
    "coreg_bbr = Node(FLIRT(dof=6,\n",
    "                       cost='bbr',\n",
    "                       schedule=opj(os.getenv('FSLDIR'),\n",
    "                                    'etc/flirtsch/bbr.sch'),\n",
    "                       output_type='NIFTI_GZ'),\n",
    "                 name=\"coreg_bbr\")\n",
    "\n",
    "# Apply coregistration warp to functional images\n",
    "applywarp = Node(FLIRT(interp='spline',\n",
    "                       apply_isoxfm=iso_size,\n",
    "                       output_type='NIFTI'),\n",
    "                 name=\"applywarp\")\n",
    "\n",
    "# Apply coregistration warp to mean file\n",
    "applywarp_mean = Node(FLIRT(interp='spline',\n",
    "                            apply_isoxfm=iso_size,\n",
    "                            output_type='NIFTI_GZ'),\n",
    "                 name=\"applywarp_mean\")\n",
    "\n",
    "# Create a coregistration workflow\n",
    "coregwf = Workflow(name='coregwf')\n",
    "coregwf.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect all components of the coregistration workflow\n",
    "coregwf.connect([(bet_anat, segmentation, [('out_file', 'in_files')]),\n",
    "                 (segmentation, threshold, [(('partial_volume_files', get_wm),\n",
    "                                             'in_file')]),\n",
    "                 (bet_anat, coreg_pre, [('out_file', 'reference')]),\n",
    "                 (threshold, coreg_bbr, [('out_file', 'wm_seg')]),\n",
    "                 (coreg_pre, coreg_bbr, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (coreg_bbr, applywarp, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (bet_anat, applywarp, [('out_file', 'reference')]),\n",
    "                 (coreg_bbr, applywarp_mean, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (bet_anat, applywarp_mean, [('out_file', 'reference')]),\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify input & output stream\n",
    "\n",
    "Specify where the input data can be found & where and how to save the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'task_name']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('task_name', task_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "anat_file = opj('derivatives', 'fmriprep', 'sub-{subject_id}', 'anat', 'sub-{subject_id}_t1w_preproc.nii.gz')\n",
    "func_file = opj('sub-{subject_id}', 'ses-test', 'func',\n",
    "                'sub-{subject_id}_ses-test_task-{task_name}_bold.nii.gz')\n",
    "\n",
    "templates = {'anat': anat_file,\n",
    "             'func': func_file}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory='/data/ds000114'),\n",
    "                   name=\"selectfiles\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "## Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', 'sub-'),\n",
    "                 ('_task_name_', '/task-'),\n",
    "                 ('_fwhm_', 'fwhm-'),\n",
    "                 ('_roi', ''),\n",
    "                 ('_mcf', ''),\n",
    "                 ('_st', ''),\n",
    "                 ('_flirt', ''),\n",
    "                 ('.nii_mean_reg', '_mean'),\n",
    "                 ('.nii.par', '.par'),\n",
    "                 ]\n",
    "subjFolders = [('fwhm-%s/' % f, 'fwhm-%s_' % f) for f in fwhm]\n",
    "substitutions.extend(subjFolders)\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Workflow\n",
    "\n",
    "Create a workflow and connect the interface nodes and the I/O stream to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing workflow\n",
    "preproc = Workflow(name='preproc')\n",
    "preproc.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "preproc.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\n",
    "                                            ('task_name', 'task_name')]),\n",
    "                 (selectfiles, extract, [('func', 'in_file')]),\n",
    "                 (extract, mcflirt, [('roi_file', 'in_file')]),\n",
    "                 (mcflirt, slicetimer, [('out_file', 'in_file')]),\n",
    "\n",
    "                 (selectfiles, coregwf, [('anat', 'bet_anat.in_file'),\n",
    "                                         ('anat', 'coreg_bbr.reference')]),\n",
    "                 (mcflirt, coregwf, [('mean_img', 'coreg_pre.in_file'),\n",
    "                                     ('mean_img', 'coreg_bbr.in_file'),\n",
    "                                     ('mean_img', 'applywarp_mean.in_file')]),\n",
    "                 (slicetimer, coregwf, [('slice_time_corrected_file', 'applywarp.in_file')]),\n",
    "                 \n",
    "                 (coregwf, smooth, [('applywarp.out_file', 'in_files')]),\n",
    "\n",
    "                 (mcflirt, datasink, [('par_file', 'preproc.@par')]),\n",
    "                 (smooth, datasink, [('smoothed_files', 'preproc.@smooth')]),\n",
    "                 (coregwf, datasink, [('applywarp_mean.out_file', 'preproc.@mean')]),\n",
    "\n",
    "                 (coregwf, art, [('applywarp.out_file', 'realigned_files')]),\n",
    "                 (mcflirt, art, [('par_file', 'realignment_parameters')]),\n",
    "\n",
    "                 (coregwf, datasink, [('coreg_bbr.out_matrix_file', 'preproc.@mat_file'),\n",
    "                                      ('bet_anat.out_file', 'preproc.@brain')]),\n",
    "                 (art, datasink, [('outlier_files', 'preproc.@outlier_files'),\n",
    "                                  ('plot_files', 'preproc.@plot_files')]),\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the workflow\n",
    "\n",
    "It always helps to visualize your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "preproc.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph_detailed.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Now that everything is ready, we can run the preprocessing workflow. Change ``n_procs`` to the number of jobs/cores you want to use. **Note** that if  you're using a Docker container and FLIRT fails to run without any good reason, you might need to change memory settings in the Docker preferences (6 GB should be enough for this workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect output\n",
    "\n",
    "Let's check the structure of the output folder, to see if we have everything we wanted to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /output/datasink/preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "Let's check the effect of the different smoothing kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "out_path = '/output/datasink/preproc/sub-01/task-fingerfootlips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(\n",
    "    '/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz',\n",
    "    title=\"T1\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(opj(out_path, 'sub-01_ses-test_task-fingerfootlips_bold_mean.nii.gz'),\n",
    "                  title=\"fwhm = 0mm\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(image.mean_img(opj(out_path, 'fwhm-4_ssub-01_ses-test_task-fingerfootlips_bold.nii')),\n",
    "                  title=\"fwhm = 4mm\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(image.mean_img(opj(out_path, 'fwhm-8_ssub-01_ses-test_task-fingerfootlips_bold.nii')),\n",
    "                  title=\"fwhm = 8mm\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's investigate the motion parameters. How much did the subject move and turn in the scanner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "par = np.loadtxt('/output/datasink/preproc/sub-01/task-fingerfootlips/sub-01_ses-test_task-fingerfootlips_bold.par')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "axes[0].set_ylabel('rotation (radians)')\n",
    "axes[0].plot(par[0:, :3])\n",
    "axes[1].plot(par[0:, 3:])\n",
    "axes[1].set_xlabel('time (TR)')\n",
    "axes[1].set_ylabel('translation (mm)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a rather drastic motion around volume 102. Let's check if the outliers detection algorithm was able to pick this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outlier_ids = np.loadtxt('/output/datasink/preproc/sub-01/task-fingerfootlips/art.sub-01_ses-test_task-fingerfootlips_bold_outliers.txt')\n",
    "print('Outliers were detected at volumes: %s' % outlier_ids)\n",
    "\n",
    "from IPython.display import SVG\n",
    "SVG(filename='/output/datasink/preproc/sub-01/task-fingerfootlips/plot.sub-01_ses-test_task-fingerfootlips_bold.svg')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
